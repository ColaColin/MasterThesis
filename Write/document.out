\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Previous work}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Monte Carlo Tree Search}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{AlphaZero}{section.2}% 4
\BOOKMARK [3][-]{subsubsection.2.2.1}{The AlphaZero algorithm}{subsection.2.2}% 5
\BOOKMARK [2][-]{subsection.2.3}{Extensions to AlphaZero}{section.2}% 6
\BOOKMARK [3][-]{subsubsection.2.3.1}{Network and training modifications}{subsection.2.3}% 7
\BOOKMARK [3][-]{subsubsection.2.3.2}{Modification of the tree search}{subsection.2.3}% 8
\BOOKMARK [3][-]{subsubsection.2.3.3}{Learning target modifications}{subsection.2.3}% 9
\BOOKMARK [3][-]{subsubsection.2.3.4}{Training data enhancements}{subsection.2.3}% 10
\BOOKMARK [1][-]{section.3}{Experimental Setup}{}% 11
\BOOKMARK [2][-]{subsection.3.1}{Network architecture}{section.3}% 12
\BOOKMARK [2][-]{subsection.3.2}{Testing on Connect 4}{section.3}% 13
\BOOKMARK [3][-]{subsubsection.3.2.1}{Generating Connect 4 datasets}{subsection.3.2}% 14
\BOOKMARK [2][-]{subsection.3.3}{Evaluation of training costs}{section.3}% 15
\BOOKMARK [2][-]{subsection.3.4}{Supervised training}{section.3}% 16
\BOOKMARK [2][-]{subsection.3.5}{Baseline}{section.3}% 17
\BOOKMARK [3][-]{subsubsection.3.5.1}{Hyperparameter search}{subsection.3.5}% 18
\BOOKMARK [2][-]{subsection.3.6}{Extended Baseline}{section.3}% 19
\BOOKMARK [3][-]{subsubsection.3.6.1}{Remove duplicate positions}{subsection.3.6}% 20
\BOOKMARK [3][-]{subsubsection.3.6.2}{Cyclic learning rate}{subsection.3.6}% 21
\BOOKMARK [3][-]{subsubsection.3.6.3}{Improved training window}{subsection.3.6}% 22
\BOOKMARK [3][-]{subsubsection.3.6.4}{Playout Caps}{subsection.3.6}% 23
\BOOKMARK [3][-]{subsubsection.3.6.5}{Predicting the opponent's reply.}{subsection.3.6}% 24
\BOOKMARK [3][-]{subsubsection.3.6.6}{Improving the network structure}{subsection.3.6}% 25
\BOOKMARK [2][-]{subsection.3.7}{Baseline results}{section.3}% 26
\BOOKMARK [1][-]{section.4}{Investigated novel ideas}{}% 27
\BOOKMARK [2][-]{subsection.4.1}{Using the self-playing phase as an evolutionary process}{section.4}% 28
\BOOKMARK [3][-]{subsubsection.4.1.1}{Implementation}{subsection.4.1}% 29
\BOOKMARK [3][-]{subsubsection.4.1.2}{Evolution of players}{subsection.4.1}% 30
\BOOKMARK [3][-]{subsubsection.4.1.3}{Selection of hyperparameters}{subsection.4.1}% 31
\BOOKMARK [3][-]{subsubsection.4.1.4}{Experiments}{subsection.4.1}% 32
\BOOKMARK [3][-]{subsubsection.4.1.5}{Requirements for evolution to succeed}{subsection.4.1}% 33
\BOOKMARK [3][-]{subsubsection.4.1.6}{Novelty search as an optimization target}{subsection.4.1}% 34
\BOOKMARK [2][-]{subsection.4.2}{Playing games as trees}{section.4}% 35
\BOOKMARK [3][-]{subsubsection.4.2.1}{Implementation}{subsection.4.2}% 36
\BOOKMARK [3][-]{subsubsection.4.2.2}{Resetting games to a position before a likely mistake}{subsection.4.2}% 37
\BOOKMARK [3][-]{subsubsection.4.2.3}{Explore the game tree in the same fashion as MCTS}{subsection.4.2}% 38
\BOOKMARK [2][-]{subsection.4.3}{Using network internal features as auxiliary targets}{section.4}% 39
\BOOKMARK [3][-]{subsubsection.4.3.1}{Implementation}{subsection.4.3}% 40
\BOOKMARK [3][-]{subsubsection.4.3.2}{Supervised}{subsection.4.3}% 41
\BOOKMARK [3][-]{subsubsection.4.3.3}{AlphaZero runs}{subsection.4.3}% 42
\BOOKMARK [3][-]{subsubsection.4.3.4}{Growing the network}{subsection.4.3}% 43
\BOOKMARK [1][-]{section.5}{Conclusion}{}% 44

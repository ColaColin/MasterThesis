# Run Name: one_cycle_test_1
# Run ID:  11a59092-48a5-454d-82fb-0f3ab4f87840
# Run SHA: 8c6c29b20ef53c7e9819a1f1e149b93011b37497
reporter:
  name: DistributedReporter
  packageSize: 1024

updater:
  name: DistributedNetworkUpdater2
  storage: /tmp/x0_networks

mnk:
  name: Connect4GameState
  m: 7
  n: 6
  k: 4

optimizerArgs:
  name: dict
  weight_decay: 0.0001
  momentum: 0.9
  lr: 0.2

lrcycle:
  name: OneCycleSchedule
  peak: 0.35
  end: 0.7
  baseVal: 0.02
  peakVal: 0.2
  endVal: 0.002
  dbgName: lr

momentumcycle:
  name: OneCycleSchedule
  peak: 0.35
  end: 0.7
  baseVal: 0.95
  peakVal: 0.85
  endVal: 0.95
  dbgName: momentum

resnet:
  name: PytorchPolicy
  batchSize: 256
  blocks: 5
  filters: 128
  headKernel: 3
  headFilters: 64
  extraHeadFilters: 32
  protoState: $mnk
  silent: true
  device: cuda
  lrDecider: $lrcycle
  momentumDecider: $momentumcycle
  optimizerName: torch.optim.SGD
  optimizerArgs: $optimizerArgs
  gradClipValue: 1
  valueLossWeight: 0.01

mcts:
  name: MctsPolicyIterator
  expansions: 343
  cpuct: 1.545
  rootNoise: 0.25
  drawValue: 0.6913
  alphaBase: 20.38
  fpu: 0.8545

tempDecider:
  name: TemperatureMoveDecider
  explorationPlyCount: 30

worker:
  name: LinearSelfPlayWorker
  initialState: $mnk
  policy: $resnet
  policyIterator: $mcts
  gameCount: 256
  moveDecider: $tempDecider
  gameReporter: $reporter
  policyUpdater: $updater

trainerWindow:
  name: ConstantWindowSizeManager
  size: 2000000
  minimumSize: 8192
  iterationSize: 300000

trainer:
  name: StreamTrainingWorker2
  windowManager: $trainerWindow
  policy: $resnet
  batchSize: 1024